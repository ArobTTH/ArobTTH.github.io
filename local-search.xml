<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>「CUDA入门」01：第一个CUDA程序</title>
    <link href="/2022/04/10/cuda-01/"/>
    <url>/2022/04/10/cuda-01/</url>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/ArobTTH/Pic_Flow/XiaoJi/20220411090848.png" alt="题图 皮衣刀客黄仁勋"></p><h1 id="「CUDA入门」01：第一个CUDA程序"><a href="#「CUDA入门」01：第一个CUDA程序" class="headerlink" title="「CUDA入门」01：第一个CUDA程序"></a>「CUDA入门」01：第一个CUDA程序</h1><h2 id="写在开始之前"><a href="#写在开始之前" class="headerlink" title="写在开始之前"></a>写在开始之前</h2><p>我硕士课题做了一点沸腾冷凝过程的两相流动力学模拟，其中用到了<a href="https://en.wikipedia.org/wiki/Lattice_Boltzmann_methods">格子玻尔兹曼方法 (LBM)</a> 。因为整个CFD模拟的核心部分是自编程实现的，<del>对非cs科班出身的我来说</del>，在学习过程自然是遇到了不少流体力学本身之外的麻烦，其中就涉及到<a href="https://en.wikipedia.org/wiki/High-performance_computing">高性能计算</a> 领域的问题（如何让代码跑得更快？）。考虑到LBM算法也是一类极适合于GPU并行的算法，正好手里也有一张性能不错的30系显卡（<del>CDPR我真谢谢你</del>），我就把目光从OpenMP之类的CPU并行框架上挪到CUDA上了。本系列主要是个人CUDA学习的小结归纳，如果这些文章能对跟我一样的<strong>编程苦手</strong>有所帮助，那就再好不过了。</p><div class="note note-info">            <p>这是我目前的开发平台(RYPC2020)，软件以及相关版本：</p><ul><li>CPU: AMD 5600X (<a href="mailto:&#x36;&#x43;&#x31;&#50;&#x54;&#64;&#52;&#x2e;&#54;&#x47;&#x48;&#122;">&#x36;&#x43;&#x31;&#50;&#x54;&#64;&#52;&#x2e;&#54;&#x47;&#x48;&#122;</a>)</li><li>GPU: NVIDIA RTX3070 (GIGABYTE Vision2.0)</li><li>RAM: HOF 8G×4 (3600MHz@c18)</li><li>Storage: Samsung 970 evo plus (2T)</li><li>IDE: CLion 2021.3.4</li><li>CMake: VERSION 3.21</li><li>Compiler：MSVC (amd64)</li></ul>          </div><h2 id="CUDA是什么"><a href="#CUDA是什么" class="headerlink" title="CUDA是什么"></a>CUDA是什么</h2><div class="note note-info">            <p><strong>CUDA</strong>（<strong>C</strong>ompute <strong>U</strong>nified <strong>D</strong>evice <strong>A</strong>rchitecture），<strong>统一计算架构</strong>是由英伟达<a href="https://zh.wikipedia.org/wiki/NVIDIA">NVIDIA</a>所推出的一种集成技术，是该公司对于<a href="https://zh.wikipedia.org/wiki/GPGPU">GPGPU</a>的正式名称。透过这个技术，用户可利用NVIDIA的<a href="https://zh.wikipedia.org/wiki/GeForce_8">GeForce 8</a>以后的GPU和较新的<a href="https://zh.wikipedia.org/wiki/Quadro">Quadro</a> <a href="https://zh.wikipedia.org/wiki/GPU">GPU</a>进行计算<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="维基百科对CUDA的介绍">[1]</span></a></sup>。</p><div align="right">——维基百科对CUDA的描述</div>          </div><p>简而言之，NVIDIA通过开发CUDA架构，使得原本主要负责图形计算GPU芯片，现在也可以通过CUDA的接口，在具有NVIDIA Gefore/Quadro/Tesla显卡的设备上实现<strong>通用计算</strong>了。在此之前苹果公司开发的<a href="https://zh.wikipedia.org/wiki/OpenCL">OpenCL</a>也是一个异构计算框架，只不过对于具有NVIDIA显卡的设备而言，CUDA的性能更好，发展更快，而OpenCL的主要优势在于能更好的兼容AMD和Intel的设备。随着NVIDIA工程师的不懈努力，以及计算机图形学、人工智能，机器学习的持续火热，目前CUDA已经成为世界上使用最广泛的并行计算平台<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="刘文志等《OpenCL异构并行计算：原理、机制与优化实践》">[2]</span></a></sup>。CUDA在各个平台的配置教程，中文互联网上都有比较详细的讲解<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="CLion配置CUDA">[3]</span></a></sup><sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="VS2019配置CUDA">[4]</span></a></sup><sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="VScode配置CUDA">[5]</span></a></sup>，这里就不过多赘述。</p><h2 id="第一个CUDA程序"><a href="#第一个CUDA程序" class="headerlink" title="第一个CUDA程序"></a>第一个CUDA程序</h2><p>在配置好编译环境之后，就可以写我们的第一个CUDA程序了，先上代码。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;cstdio&gt;</span></span><br><br><span class="hljs-comment">//全局核函数，可以被CPU调用</span><br><span class="hljs-function">__global__ <span class="hljs-keyword">void</span> <span class="hljs-title">helloWorld</span> <span class="hljs-params">()</span> </span>&#123;<br><br>    <span class="hljs-comment">//std::cout&lt;&lt; &quot;hello world from GPU!&quot; &lt;&lt; std::endl; 使用cout报错</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world from GPU!\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><br>    <span class="hljs-comment">//main函数中调用核函数</span><br>    helloWorld&lt;&lt;&lt;<span class="hljs-number">1</span>,<span class="hljs-number">1</span>&gt;&gt;&gt;();<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>终端输出结果：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">hello world from GPU!<br></code></pre></div></td></tr></table></figure><p><span class="label label-warning">程序虽然简单，但其中有几点需要注意：</span></p><p>CUDA属于异构计算框架，需要区分函数是在CPU上运行还是GPU上运行，其中CUDA在device上并行执行的函数被称之为<strong>核函数 (Kernal Function)</strong> ，用标号<code>__global__</code>符号声明。CUDA中将函数依照调用规则分为以下三类<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="知乎用户@小小将对核函数的叙述">[6]</span></a></sup>：</p><blockquote><ul><li><code>__global__</code>：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是<code>void</code>，不支持可变参数参数，不能成为类成员函数。注意用<code>__global__</code>定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。</li><li><code>__device__</code>：在device上执行，单仅可以从device中调用，不可以和<code>__global__</code>同时用。</li><li><code>__host__</code>：在host上执行，仅可以从host上调用，一般省略不写，不可以和<code>__global__</code>同时用，但可和<code>__device__</code>，此时函数会在device和host都编译。</li></ul></blockquote><p>调用Kernal时，需要指定设备中参与运算的GPU并行线程的数量，用<code>&lt;&lt;&lt;grid,block&gt;&gt;&gt;</code>表示。<strong>实际上这也是CUDA中最重要的问题之一</strong>，这里我们设置的是<code>&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>,指代我们只用调用一个线程去执行打印<code>hello world</code>的任务，实际上，如果我们在调用时设置为<code>&lt;&lt;&lt;2,2&gt;&gt;&gt;</code>则会得到四条<code>hello world</code>的信息，但是我们其实只调用了Kernal一次，关于这个问题我们将会在之后的文章中详细说明。</p><p>这里还需要注意，当使你在<code>__global__</code>中使用c++输入/输出流<code>&lt;iostream&gt;</code>时，编译器会报错，这是因为NVIDIA 目前还没有在CUDA设备上实现任何形式的C++ iostream样式的I/O支持。但是<code>printf</code>是可以正常输出的，这是因为NVIDIA通过对<code>printf</code>函数重载，为所有ABI (compute capability计算能力 &gt;= 2.0) 的CUDA硬件提供了运行的支持。只要我们包含<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>的头文件就能正常调用<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stackoverflow上对iostream在gpu设备上输出报错的解答">[7]</span></a></sup>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这一节我们简单介绍了CUDA的基本概念，以及用最简单的代码实现了GPU版本的“hello world”，下一节我们将从一个简单的GPU计算程序入手，进一步讨论CUDA中的重点：数据在CPU和GPU之间拷贝的问题。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://zh.wikipedia.org/wiki/CUDA">维基百科对CUDA的介绍</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://zh.de1lib.org/book/18192576/2a57e1">刘文志等《OpenCL异构并行计算：原理、机制与优化实践》</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://blog.csdn.net/luyuyingyingying/article/details/114448267">CLion配置CUDA</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://blog.csdn.net/u011314529/article/details/51353097">VS2019配置CUDA</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://blog.csdn.net/lumping/article/details/107658678">VScode配置CUDA</a><a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/34587739">知乎用户@小小将对核函数的叙述</a><a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a href="https://stackoverflow.com/questions/36855469/using-thrust-with-printf-cout">Stackoverflow上对iostream在gpu设备上输出报错的解答</a><a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
      <tag>GPU</tag>
      
      <tag>编程</tag>
      
      <tag>并行计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录 20210819</title>
    <link href="/2021/08/19/20210819/"/>
    <url>/2021/08/19/20210819/</url>
    
    <content type="html"><![CDATA[<h1 id="记录-20210819"><a href="#记录-20210819" class="headerlink" title="记录 20210819"></a>记录 20210819</h1><p>最近发生了很多有意思的事，让这个已经断更了4个月之久的小博客似乎又有了更新的动力。<del>（其实过去四个月也有挺多新鲜事，不过暂且不表吧）</del> 总而言之，我决定把脑子里的一些想法不定期倒出来，以这个<code>记录</code>系列的形式记录。</p><blockquote><p align="right">——RY，你真的是想做blog而不是做资源分享站吗？</p></blockquote><h2 id="关于《EVA终》"><a href="#关于《EVA终》" class="headerlink" title="关于《EVA终》"></a>关于《EVA终》</h2><p><strong>EVA最后一部剧场版上线流媒体</strong>算是其中最想拉出来聊一聊的事，看了两遍，但是脑子里始终没理一条很明确的线索，把这部作品给我的众多emo表达好。那暂且只分成三层<strong>简单</strong>聊聊好了（纯粹闲扯，被窝里抱个电脑敲字，没找资料有可能口胡）。</p><p align="middle">-------- 前方大规模括号来袭 --------</p><ul><li>《EVA终》的皮相</li></ul><p>先说结论，如果抛去其中很多3D场景制作，对我来说《EVA终》的皮相无疑是<em>优秀</em>的。具体表现为新手法的运用（包括但不限于模拟手持相机实拍镜头（明日香喂真嗣食物），延时摄影模拟（甚至有模拟了摄像机震动和丢帧），空间站表现失重动态的<strong>转描</strong>，感觉有一卡甚至用（模拟？）了赛璐璐作画等…）；新剧场版系列平均水平的配乐，宇多田光的ED从未如此恰如其分（结合MV实用更香，印象中镜头里的光从未笑得如此灿烂），ps：<em>Hand of Fate</em>，几首曲子里最喜欢这个；尽管男主真嗣在A-part的表现稍显沉闷，但得益于黑绫波对于绫波系列复制人情感模块上的史诗级贡献，加之前作大量包袱被回收，本作节奏上没有出现太大问题。 <del>（观影体验吊打《EVA Q》）</del></p><ul><li>《EVA终》的肉相</li></ul><blockquote><p>几天前，还深陷emo中的我拟了这样一个标题 <em>“我所理解的《EVA：终》——关于归还、联结与告别的故事“</em>。 <del>虽然没憋出正文</del></p></blockquote><p>《EVA终》到底说了什么故事呢？<del>抛去外衣</del>，我觉得其实说了一个关于<strong>归还</strong>、<strong>联结</strong>与<strong>告别</strong>的故事。</p><p><strong>归还</strong>，或者说<strong>还原</strong>是旧状态的再平衡，在EVA中都带有褒义（为什么这里不多说）。具体表现为1、Wille想复原被冲击损毁的生命，开头10分钟还原部分巴黎地区等；2、读书吧里小孩归还黑绫波掉下的土豆；3、绫波归还SDAT给真嗣，真嗣归还SDAT给源渡。<strong>归还</strong>可以看作是事物向消极向积极状态前进的<strong>契机</strong>，<del>导火索</del>。</p><p>而<strong>归还</strong>的目的在于更深一步的<strong>联结</strong>。<strong>联结</strong>通常象征着一段关系的升格，一种积极的进化。形式上的联结的标志，典型如1、黑绫波与孩子第一次握手；2、黑绫波向真嗣伸手，说这是一种建立“羁绊“的方式；3、additional补完之时，真嗣向渚薰、司令等伸手，建立联结（羁绊）；4、片尾真希波向真嗣伸手。<strong>联结</strong>可以认为是一段新关系建立的“起始”，同时我也觉得<u>“无畏被伤害，积极地追求与他人的联结”</u> 是EVA系列真正想启发其读者的核心观点。</p><p>而正如片名一般，由于种种原因，<strong>联结</strong>将会到达它的<strong>终结</strong>。<del>就像高能与高温状态不会稳定，一个有限环境最终会到来“热寂”</del> 我们最终需要与旧关系<strong>告别</strong>。而在片中主要表达了这样几次告别1、黑绫波与真嗣告别；2、美里（加持）与众人告别；3、真嗣向明日香告别；4、真希波与EVA机体告别；<del>5、主角团与观众告别</del>。而除了1、黑绫波向真嗣告别之时，我感受到了熟悉的“恶意”之外，庵野似乎也有意向我们传达<strong>告别</strong>的多种积极意味。</p><p align="middle">-------- one more point --------</p><p>为了给上述内容打辅助，<strong>温柔感</strong>是本片着重想凸显的的气质之一。车厢下生活的母猫，水稻田里插秧耕作的农民，小镇上“生活”蓬生的烟火气息与”孕育”带来的温软气息扑面而来。搭配锦织哥哥偏可爱活泼系的监修，本作治愈力量满满。<del>（二十多年来，我从未感受到EVA如此温柔</del>。</p><p align="middle">-------- 全是私货 胡言乱语 没有逻辑 --------</p><ul><li>《EVA终》的骨相</li></ul><p>《EVA》（旧）之所以是《EVA》，《EVA》区别于其他任何作品的原因，是因为作为创作者的庵野秀明，有真正想在《EVA》中表达的内容，而《EVA》所想要表达的主题带有与其本人强相关的，非常独特和个人化的情绪。而旧版更有之独特的社会背景，使之甚至成了一个时代的图腾。</p><p>由于种种原因，我们得到了一次宝贵的，透过作品窥视庵野自身“补完”结局的机会——《福音战士新剧场版》系列。<del>总的来说，新剧场版系列前三作中，真嗣从旧版“抑郁”成长为“躁郁”。</del> 比起真嗣在《EVA终》中的成长所象征的，我主观更愿意从一些细节中感受庵野本人的变化。<strong>遗憾的是，新作没有打动我</strong>，但这丝毫不妨碍我认为庵野比以前更幸福了。对于一个已经缔造了一个奇迹的创作者，我认为<strong>他本人能够幸福，显然比再缔造一次奇迹有意义得多</strong>。<del>（我已经被补完）</del></p><p>我在看《EVA终》之后，又看了一遍《Air/真心为你》，我顿感“超越旧版EVA”这个命题本来就是不可能完成的任务。（Air中“美里给真嗣大人的吻“，穿插”二号机大战量产机“的片段无数次震撼了我，而真心为你中神乎其技的表达又使得EVA最终成为EVA）。</p><p><del>至于新作为什么没能打动我，大概是我知道，我的蒙娜丽莎还没有出现吧，<strong>（bushi）</strong>.</del></p>]]></content>
    
    
    <categories>
      
      <category>记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
