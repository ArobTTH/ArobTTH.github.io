<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>「CUDA入门」01：第一个CUDA程序</title>
    <link href="/2022/04/10/cuda-01/"/>
    <url>/2022/04/10/cuda-01/</url>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/ArobTTH/Pic_Flow/XiaoJi/20220411090848.png" alt="题图 皮衣刀客黄仁勋"></p><h1 id="「CUDA入门」01：第一个CUDA程序"><a href="#「CUDA入门」01：第一个CUDA程序" class="headerlink" title="「CUDA入门」01：第一个CUDA程序"></a>「CUDA入门」01：第一个CUDA程序</h1><h2 id="写在开始之前"><a href="#写在开始之前" class="headerlink" title="写在开始之前"></a>写在开始之前</h2><p>我硕士课题做了一点沸腾冷凝过程的两相流动力学模拟，其中用到了<a href="https://en.wikipedia.org/wiki/Lattice_Boltzmann_methods">格子玻尔兹曼方法 (LBM)</a> 。因为整个CFD模拟的核心部分是自编程实现的，<del>对非cs科班出身的我来说</del>，在学习过程自然是遇到了不少流体力学本身之外的麻烦，其中就涉及到<a href="https://en.wikipedia.org/wiki/High-performance_computing">高性能计算</a> 领域的问题（如何让代码跑得更快？）。考虑到LBM算法也是一类极适合于GPU并行的算法，正好手里也有一张性能不错的30系显卡（<del>CDPR我真谢谢你</del>），我就把目光从OpenMP之类的CPU并行框架上挪到CUDA上了。本系列主要是个人CUDA学习的小结归纳，如果这些文章能对跟我一样的<strong>编程苦手</strong>有所帮助，那就再好不过了。</p><div class="note note-info">            <p>这是我目前的开发平台(RYPC2020)，软件以及相关版本：</p><ul><li>CPU: AMD 5600X (<a href="mailto:&#x36;&#67;&#49;&#50;&#84;&#64;&#52;&#46;&#54;&#x47;&#x48;&#x7a;">&#x36;&#67;&#49;&#50;&#84;&#64;&#52;&#46;&#54;&#x47;&#x48;&#x7a;</a>)</li><li>GPU: NVIDIA RTX3070 (GIGABYTE Vision2.0)</li><li>RAM: HOF 8G×4 (3600MHz@c18)</li><li>Storage: Samsung 970 evo plus (2T)</li><li>IDE: CLion 2021.3.4</li><li>CMake: VERSION 3.21</li><li>Compiler：MSVC (amd64)</li></ul>          </div><h2 id="CUDA是什么"><a href="#CUDA是什么" class="headerlink" title="CUDA是什么"></a>CUDA是什么</h2><div class="note note-info">            <p><strong>CUDA</strong>（<strong>C</strong>ompute <strong>U</strong>nified <strong>D</strong>evice <strong>A</strong>rchitecture），<strong>统一计算架构</strong>是由英伟达<a href="https://zh.wikipedia.org/wiki/NVIDIA">NVIDIA</a>所推出的一种集成技术，是该公司对于<a href="https://zh.wikipedia.org/wiki/GPGPU">GPGPU</a>的正式名称。透过这个技术，用户可利用NVIDIA的<a href="https://zh.wikipedia.org/wiki/GeForce_8">GeForce 8</a>以后的GPU和较新的<a href="https://zh.wikipedia.org/wiki/Quadro">Quadro</a> <a href="https://zh.wikipedia.org/wiki/GPU">GPU</a>进行计算<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="维基百科对CUDA的介绍">[1]</span></a></sup>。</p><div align="right">——维基百科对CUDA的描述</div>          </div><p>简而言之，NVIDIA通过开发CUDA架构，使得原本主要负责图形计算GPU芯片，现在也可以通过CUDA的接口，在具有NVIDIA Gefore/Quadro/Tesla显卡的设备上实现<strong>通用计算</strong>了。在此之前苹果公司开发的<a href="https://zh.wikipedia.org/wiki/OpenCL">OpenCL</a>也是一个异构计算框架，只不过对于具有NVIDIA显卡的设备而言，CUDA的性能更好，发展更快，而OpenCL的主要优势在于能更好的兼容AMD和Intel的设备。随着NVIDIA工程师的不懈努力，以及计算机图形学、人工智能，机器学习的持续火热，目前CUDA已经成为世界上使用最广泛的并行计算平台<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="刘文志等《OpenCL异构并行计算：原理、机制与优化实践》">[2]</span></a></sup>。CUDA在各个平台的配置教程，中文互联网上都有比较详细的讲解<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="CLion配置CUDA">[3]</span></a></sup><sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="VS2019配置CUDA">[4]</span></a></sup><sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="VScode配置CUDA">[5]</span></a></sup>，这里就不过多赘述。</p><h2 id="第一个CUDA程序"><a href="#第一个CUDA程序" class="headerlink" title="第一个CUDA程序"></a>第一个CUDA程序</h2><p>在配置好编译环境之后，就可以写我们的第一个CUDA程序了，先上代码。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;cstdio&gt;</span></span><br><br><span class="hljs-comment">//全局核函数，可以被CPU调用</span><br><span class="hljs-function">__global__ <span class="hljs-keyword">void</span> <span class="hljs-title">HelloWorld</span> <span class="hljs-params">()</span> </span>&#123;<br><br>    <span class="hljs-comment">//std::cout&lt;&lt; &quot;hello world form GPU!&quot; &lt;&lt; std::endl; 使用cout报错</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world form GPU!\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><br>    <span class="hljs-comment">//main函数中调用核函数</span><br>    HelloWorld&lt;&lt;&lt;<span class="hljs-number">1</span>,<span class="hljs-number">1</span>&gt;&gt;&gt;();<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>终端输出结果：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">hello world form GPU!<br></code></pre></div></td></tr></table></figure><p><span class="label label-warning">程序虽然简单，但其中有几点需要注意：</span></p><p>CUDA属于异构计算框架，需要区分函数是在CPU上运行还是GPU上运行，其中CUDA在device上并行执行的函数被称之为<strong>核函数 (Kernal Function)</strong> ，用标号<code>__global__</code>符号声明。CUDA中将函数依照调用规则分为以下三类<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="知乎用户@小小将对核函数的叙述">[6]</span></a></sup>：</p><blockquote><ul><li><code>__global__</code>：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是<code>void</code>，不支持可变参数参数，不能成为类成员函数。注意用<code>__global__</code>定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。</li><li><code>__device__</code>：在device上执行，单仅可以从device中调用，不可以和<code>__global__</code>同时用。</li><li><code>__host__</code>：在host上执行，仅可以从host上调用，一般省略不写，不可以和<code>__global__</code>同时用，但可和<code>__device__</code>，此时函数会在device和host都编译。</li></ul></blockquote><p>调用Kernal时，需要指定设备中参与运算的GPU并行线程的数量，用<code>&lt;&lt;&lt;grid,block&gt;&gt;&gt;</code>表示。<strong>实际上这也是CUDA中最重要的问题之一</strong>，这里我们设置的是<code>&lt;&lt;&lt;1,1&gt;&gt;&gt;</code>,指代我们只用调用一个线程去执行打印<code>hello world</code>的任务，实际上，如果我们在调用时设置为<code>&lt;&lt;&lt;2,2&gt;&gt;&gt;</code>则会得到四条<code>hello world</code>的信息，但是我们其实只调用了Kernal一次，关于这个问题我们将会在之后的文章中详细说明。</p><p>这里还需要注意，当使你在<code>__global__</code>中使用c++输入/输出流<code>&lt;iostream&gt;</code>时，编译器会报错，这是因为NVIDIA 目前还没有在CUDA设备上实现任何形式的C++ iostream样式的I/O支持。但是<code>printf</code>是可以正常输出的，这是因为NVIDIA通过对<code>printf</code>函数重载，为所有ABI (compute capability计算能力 &gt;= 2.0) 的CUDA硬件提供了运行的支持。只要我们包含<code>&lt;cstdio&gt;</code>或<code>&lt;stdio.h&gt;</code>的头文件就能正常调用<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stackoverflow上对iostream在gpu设备上输出报错的解答">[7]</span></a></sup>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这一节我们简单介绍了CUDA的基本概念，以及用最简单的代码实现了GPU版本的“hello world”，下一节我们将从一个简单的GPU计算程序入手，进一步讨论CUDA中的重点：数据在CPU和GPU之间拷贝的问题。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://zh.wikipedia.org/wiki/CUDA">维基百科对CUDA的介绍</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://zh.de1lib.org/book/18192576/2a57e1">刘文志等《OpenCL异构并行计算：原理、机制与优化实践》</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://blog.csdn.net/luyuyingyingying/article/details/114448267">CLion配置CUDA</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://blog.csdn.net/u011314529/article/details/51353097">VS2019配置CUDA</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://blog.csdn.net/lumping/article/details/107658678">VScode配置CUDA</a><a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/34587739">知乎用户@小小将对核函数的叙述</a><a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a href="https://stackoverflow.com/questions/36855469/using-thrust-with-printf-cout">Stackoverflow上对iostream在gpu设备上输出报错的解答</a><a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>编程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
      <tag>GPU</tag>
      
      <tag>编程</tag>
      
      <tag>并行计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
